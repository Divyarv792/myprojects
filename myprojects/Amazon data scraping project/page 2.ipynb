{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9498a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from requests_html import HTMLSession\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "s=HTMLSession()\n",
    "url=\"https://www.amazon.in/s?k=bags&page=2&crid=2M096C61O4MLT&qid=1693203926&sprefix=ba%2Caps%2C283&ref=sr_pg_1\"\n",
    "\n",
    "def all_datas(url):\n",
    "    headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "    data = s.get(url, headers=headers)\n",
    "    #print(data)getting response 503 after 2url\n",
    "    soup=bs(data.content,'lxml')\n",
    "    datas(soup)\n",
    "    return soup\n",
    "   \n",
    "def datas(soup):\n",
    "    header=['Product Name','Price','Rating','No of Reviews','ASIN','Manufacturer','URL']\n",
    "    with open(r'C:\\Users\\Naveen\\Desktop\\data science\\data scrapping\\Amazon data scraping project\\CSV folder\\page2.csv','w', newline='',encoding='UTF8')as f:\n",
    "        writer=csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "    products=soup.find_all('div', class_=['sg-col-20-of-24 s-result-item s-asin sg-col-0-of-12 sg-col-16-of-20 sg-col s-widget-spacing-small sg-col-12-of-16', 'sg-col-20-of-24 s-result-item s-asin sg-col-0-of-12 sg-col-16-of-20 AdHolder sg-col s-widget-spacing-small sg-col-12-of-16'])\n",
    "    for product in products: \n",
    "        product_name=product.find('span',class_ = 'a-size-medium a-color-base a-text-normal').text\n",
    "        product_price=product.find('span', class_= 'a-price-whole').text\n",
    "        if product.find('span',class_='a-size-base s-underline-text'):\n",
    "            No_of_reviews=product.find('span',class_='a-size-base s-underline-text').text.strip('()')\n",
    "        else: \n",
    "            No_of_reviews='No reviews'\n",
    "        if product.find('span',class_='a-icon-alt'):\n",
    "            product_rating=product.find('span',class_='a-icon-alt').text\n",
    "        else:\n",
    "            product_rating='No rating'\n",
    "        product_URL=product.h2.a['href']\n",
    "        new_URL=product_URL.replace(product_URL,'https://www.amazon.in/'+product_URL)\n",
    "        header = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "        c=HTMLSession()\n",
    "        newdata = c.get(new_URL, headers=header)\n",
    "        sp=bs(newdata.content,'lxml')\n",
    "        if sp.find('ul',class_='a-unordered-list a-nostyle a-vertical a-spacing-none detail-bullet-list'):\n",
    "            reqdata=sp.find('ul',class_='a-unordered-list a-nostyle a-vertical a-spacing-none detail-bullet-list')\n",
    "            req=reqdata.find_all('span')\n",
    "            for r in req:\n",
    "                x='ASIN'\n",
    "                if x in r.get_text():\n",
    "                    ASIN=r.get_text().split(':')[1].replace(' ','').strip().replace('\\n','')  \n",
    "                    break\n",
    "            for r in req:\n",
    "                y='Manufacturer'\n",
    "                if y in r.get_text():\n",
    "                    Manufacturer=r.get_text().split(':')[1].replace(' ','').strip().replace('\\n','')\n",
    "                    break\n",
    "        elif sp.find('table',{'id':'productDetails_detailBullets_sections1'}):\n",
    "            reqdata=sp.find('table',{'id':'productDetails_detailBullets_sections1'})\n",
    "            req=reqdata.find_all('tr')\n",
    "            for r in req:\n",
    "                x='ASIN'\n",
    "                if x in r.text:\n",
    "                    ASIN=r.td.text.strip()\n",
    "                    break\n",
    "            for r in req:\n",
    "                x='Manufacturer'\n",
    "                if x in r.text:\n",
    "                    Manufacturer=r.td.text.strip()\n",
    "                    break\n",
    "    #header=['Product Name','Price','Rating','No of Reviews','ASIN','Manufacturer','URL']\n",
    "        data=(product_name,product_price,product_rating,No_of_reviews,ASIN,Manufacturer,new_URL)\n",
    "        with open(r'C:\\Users\\Naveen\\Desktop\\data science\\data scrapping\\Amazon data scraping project\\CSV folder\\page2.csv','a+', newline='',encoding='UTF8')as f:\n",
    "            writer=csv.writer(f)\n",
    "            writer.writerow(data)\n",
    "\n",
    "while(True):\n",
    "    soup=all_datas(url)\n",
    "    datas(soup)\n",
    "    time.sleep(3600)\n",
    "   \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab5f47a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd88dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
